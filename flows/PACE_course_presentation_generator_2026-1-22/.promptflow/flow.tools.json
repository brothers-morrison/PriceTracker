{
  "package": {
    "promptflow.tools.llm.llm": {
      "name": "LLM",
      "description": {
        "default": "Use OpenAI-like Large Language Model for text completion or chat.",
        "aml": "Use OpenAI-like Large Language Model for text completion or chat. For more details, refer to this [document](https://aka.ms/promptflow/llm-tool).",
        "ai_studio": "Use OpenAI-like Large Language Model for text completion or chat. For more details, refer to this [document](https://aka.ms/aistudio/pf/llm-tool)."
      },
      "type": "custom_llm",
      "module": "promptflow.tools.llm",
      "function": "llm",
      "category": "llm",
      "icon": {
        "light": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAx0lEQVR4nJWSwQ2CQBBFX0jAcjgqXUgPJNiIsQQrIVCIFy8GC6ABDcGDX7Mus9n1Xz7zZ+fPsLPwH4bUg0dD2wMPcbR48Uxq4AKU4iSTDwZ1LhWXipN/B3V0J6hjBTvgLHZNonewBXrgDpzEvXSIjN0BE3AACmmF4kl5F6tNzcCoLpW0SvGovFvsb4oZ2AANcAOu4ka6axCcINN3rg654sww+CYsPD0OwjcozFNh/Qcd78tqVbCIW+n+Fky472Bh/Q6SYb1EEy8tDzd+9IsVPAAAAABJRU5ErkJggg==",
        "dark": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA2ElEQVR4nJXSzW3CQBAF4DUSTjk+Al1AD0ikESslpBIEheRALhEpgAYSWV8OGUublf/yLuP3PPNmdndS+gdwXZrYDmh7fGE/W+wXbaYd8IYm4rxJPnZ0boI3wZcdJxs/n+AwV7DFK7aFyfQdYIMLPvES8YJNf5yp4jMeeEYdWh38gXOR35YGHe5xabvQdsHv6PLi8qV6gycc8YH3iMfQu6Lh4ASr+F5Hh3XwVWnQYzUkVlX1nccplAb1SN6Y/sfgmlK64VS8wimldIv/0yj2QLkHizG0iWP4AVAfQ34DVQONAAAAAElFTkSuQmCC"
      },
      "default_prompt": "# system:\nYou are a helpful assistant.\n\n# user:\n{{question}}\n",
      "groups": [
        {
          "name": "Tools",
          "description": "Configure interactive capabilities by selecting tools for the model to use and guiding its tool call decisions.",
          "inputs": [
            "tools",
            "tool_choice"
          ],
          "ui_hints": {
            "display_style": "table"
          }
        }
      ],
      "inputs": {
        "connection": {
          "type": [
            "AzureOpenAIConnection",
            "OpenAIConnection",
            "ServerlessConnection"
          ],
          "ui_hints": {
            "index": 0
          }
        },
        "api": {
          "type": [
            "string"
          ],
          "default": "chat",
          "filter_by": {
            "input_name": "connection",
            "filter_attribute": "type",
            "values": {
              "AzureOpenAIConnection": {
                "enum": [
                  "chat",
                  "completion"
                ]
              },
              "OpenAIConnection": {
                "enum": [
                  "chat",
                  "completion"
                ]
              },
              "ServerlessConnection": {
                "enum": [
                  "chat"
                ]
              }
            }
          },
          "allow_manual_entry": true,
          "ui_hints": {
            "text_box_size": "sm",
            "index": 1
          }
        },
        "deployment_name": {
          "type": [
            "string"
          ],
          "enabled_by": "connection",
          "enabled_by_type": [
            "AzureOpenAIConnection"
          ],
          "filter_by": {
            "input_name": "api",
            "values": {
              "chat": {
                "capabilities": {
                  "chat_completion": true,
                  "exclude": {
                    "model_version": [
                      "vision-preview"
                    ]
                  }
                }
              },
              "completion": {
                "capabilities": {
                  "completion": true,
                  "include": {
                    "model_name": [
                      "gpt-35-turbo-instruct"
                    ]
                  }
                }
              }
            }
          },
          "allow_manual_entry": true,
          "is_multi_select": false,
          "ui_hints": {
            "text_box_size": "lg",
            "index": 2
          }
        },
        "model": {
          "type": [
            "string"
          ],
          "enabled_by": "connection",
          "enabled_by_type": [
            "OpenAIConnection"
          ],
          "filter_by": {
            "input_name": "api",
            "values": {
              "chat": {
                "enum": [
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0301",
                  "gpt-3.5-turbo-16k",
                  "gpt-3.5-turbo-1106",
                  "gpt-4",
                  "gpt-4-1106-preview",
                  "gpt-4-0314",
                  "gpt-4-32k",
                  "gpt-4-32k-0314"
                ]
              },
              "completion": {
                "enum": [
                  "gpt-3.5-turbo-instruct"
                ]
              }
            }
          },
          "allow_manual_entry": true,
          "is_multi_select": false,
          "ui_hints": {
            "text_box_size": "lg",
            "index": 3
          }
        },
        "temperature": {
          "default": 1,
          "type": [
            "double"
          ],
          "ui_hints": {
            "text_box_size": "xs",
            "index": 4
          }
        },
        "top_p": {
          "default": 1,
          "type": [
            "double"
          ],
          "ui_hints": {
            "text_box_size": "xs",
            "index": 5
          },
          "advanced": true
        },
        "stop": {
          "default": "",
          "type": [
            "list"
          ],
          "ui_hints": {
            "text_box_size": "md",
            "index": 6
          }
        },
        "max_tokens": {
          "default": "",
          "type": [
            "int"
          ],
          "ui_hints": {
            "text_box_size": "xs",
            "index": 7
          }
        },
        "presence_penalty": {
          "default": "",
          "type": [
            "double"
          ],
          "advanced": true,
          "ui_hints": {
            "index": 8
          }
        },
        "response_format": {
          "type": [
            "object"
          ],
          "enabled_by": "api",
          "enabled_by_value": [
            "chat"
          ],
          "advanced": false,
          "ui_hints": {
            "text_box_size": "lg",
            "index": 9
          },
          "enum": [
            {
              "type": "json_object"
            },
            {
              "type": "text"
            }
          ],
          "allow_manual_entry": true,
          "default": ""
        },
        "frequency_penalty": {
          "type": [
            "int"
          ],
          "default": "",
          "advanced": true,
          "ui_hints": {
            "text_box_size": "xs",
            "index": 10
          }
        },
        "logit_bias": {
          "type": [
            "object"
          ],
          "default": "",
          "advanced": true,
          "ui_hints": {
            "text_box_size": "lg",
            "index": 11
          }
        },
        "seed": {
          "default": "",
          "type": [
            "int"
          ],
          "enabled_by": "api",
          "enabled_by_value": [
            "chat"
          ],
          "advanced": true,
          "ui_hints": {
            "text_box_size": "xs",
            "index": 12
          }
        },
        "suffix": {
          "default": "",
          "type": [
            "string"
          ],
          "enabled_by": "api",
          "enabled_by_value": [
            "completion"
          ],
          "advanced": true,
          "ui_hints": {
            "text_box_size": "xs",
            "index": 13
          }
        },
        "logprobs": {
          "default": "",
          "type": [
            "int"
          ],
          "enabled_by": "api",
          "enabled_by_value": [
            "completion"
          ],
          "advanced": true,
          "ui_hints": {
            "text_box_size": "xs",
            "index": 14
          }
        },
        "echo": {
          "default": false,
          "type": [
            "bool"
          ],
          "enabled_by": "api",
          "enabled_by_value": [
            "completion"
          ],
          "advanced": true,
          "ui_hints": {
            "text_box_size": "xs",
            "index": 15
          }
        },
        "best_of": {
          "default": 1,
          "type": [
            "int"
          ],
          "enabled_by": "api",
          "enabled_by_value": [
            "completion"
          ],
          "advanced": true,
          "ui_hints": {
            "text_box_size": "xs",
            "index": 16
          }
        },
        "tools": {
          "type": [
            "list"
          ],
          "default": [],
          "enabled_by": "api",
          "enabled_by_value": [
            "chat"
          ],
          "ui_hints": {
            "display_style": "reusable_tool",
            "index": 17
          }
        },
        "tool_choice": {
          "type": [
            "object",
            "string"
          ],
          "default": "",
          "enabled_by": "api",
          "enabled_by_value": [
            "chat"
          ],
          "ui_hints": {
            "index": 18
          }
        }
      },
      "package": "promptflow-tools",
      "package_version": "1.6.1"
    }
  },
  "code": {
    "line_process.py": {
      "type": "python",
      "inputs": {
        "groundtruth": {
          "type": [
            "string"
          ]
        },
        "prediction": {
          "type": [
            "string"
          ]
        }
      },
      "description": "This tool processes the prediction of a single line and returns the processed result.\n\n:param groundtruth: the groundtruth of a single line.\n:param prediction: the prediction of a single line.",
      "source": "line_process.py",
      "function": "line_process"
    },
    "aggregate.py": {
      "type": "python",
      "inputs": {
        "processed_results": {
          "type": [
            "object"
          ]
        }
      },
      "description": "This tool aggregates the processed result of all lines and calculate the accuracy. Then log metric for the accuracy.\n\n:param processed_results: List of the output of line_process node.",
      "source": "aggregate.py",
      "function": "aggregate"
    },
    "Fake_LLM.py": {
      "type": "python",
      "inputs": {
        "input1": {
          "type": [
            "string"
          ]
        }
      },
      "source": "Fake_LLM.py",
      "function": "my_python_tool"
    },
    "py_single_user_qa.py": {
      "type": "python",
      "inputs": {
        "field_config": {
          "type": [
            "object"
          ]
        }
      },
      "description": "Prompts user for input based on field configuration and validates against choices.\n\nArgs:\n    field_config: Dict with 'name' and 'choices' keys\n    \nReturns:\n    str: The validated user input",
      "source": "py_single_user_qa.py",
      "function": "single_question_answer"
    },
    "py_iterator.py": {
      "type": "python",
      "inputs": {
        "field_configs": {
          "type": [
            "object"
          ]
        }
      },
      "description": "Iterate through each field config and collect answers.\n\nArgs:\n    field_configs: List of field configuration dicts\n    \nReturns:\n    List of user answers",
      "source": "py_iterator.py",
      "function": "iterate_questions"
    },
    "py_md_to_json.py": {
      "type": "python",
      "inputs": {
        "markdown_text": {
          "type": [
            "string"
          ]
        }
      },
      "description": "Convert markdown list items to JSON objects.\n\nArgs:\n    markdown_text (str): Single line or multiline markdown list items\n    \nReturns:\n    list or dict: List of JSON objects if multiline, single dict if single line\n    \nExample:\n    >>> markdown_to_json(\"- Target_Audience (role, seniority, prior knowledge):\")\n    {'name': 'Target_Audience', 'choices': ['role', 'seniority', 'prior knowledge']}",
      "source": "py_md_to_json.py",
      "function": "markdown_to_json"
    },
    "01_py_md_to_json.py": {
      "type": "python",
      "inputs": {
        "markdown_text": {
          "type": [
            "string"
          ]
        }
      },
      "description": "Convert markdown list items to JSON objects.\n\nArgs:\n    markdown_text (str): Single line or multiline markdown list items\n    \nReturns:\n    list or dict: List of JSON objects if multiline, single dict if single line\n    \nExample:\n    >>> markdown_to_json(\"- Target_Audience (role, seniority, prior knowledge):\")\n    {'name': 'Target_Audience', 'choices': ['role', 'seniority', 'prior knowledge']}",
      "source": "01_py_md_to_json.py",
      "function": "markdown_to_json"
    },
    "Pre_LLM_cache.py": {
      "type": "python",
      "inputs": {
        "input1": {
          "type": [
            "list"
          ]
        }
      },
      "source": "Pre_LLM_cache.py",
      "function": "my_python_tool"
    },
    "GPT5nano_LLM.jinja2": {
      "type": "prompt",
      "inputs": {
        "question": {
          "type": [
            "string"
          ]
        }
      },
      "source": "GPT5nano_LLM.jinja2"
    },
    "brand_and_generate_ppt.jinja2": {
      "type": "prompt",
      "inputs": {
        "text": {
          "type": [
            "string"
          ]
        }
      },
      "source": "brand_and_generate_ppt.jinja2"
    }
  }
}